{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import optbinning as optbin\n",
    "import psutil\n",
    "import json\n",
    "import os\n",
    "import datetime as dt\n",
    "import logging\n",
    "import re\n",
    "import joblib\n",
    "import gc\n",
    "import warnings\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "pd.set_option('max_columns', 300)\n",
    "pd.set_option('max_rows', 300)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('dataset.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Making train/test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2742, 260) (1176, 260) 153 70\n",
      "Wall time: 23 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y = data['target']\n",
    "X = data.drop(['target','id','default_date'],axis = 1 )\n",
    "X_1, X_2, y_1, y_2 = train_test_split(X, y,  \n",
    "                                      test_size=0.3,\n",
    "                                      random_state=23)\n",
    "print(X_1.shape, X_2.shape, sum(y_1), sum(y_2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    " train = X_1.join(y_1).reset_index(drop=True)\n",
    "test = X_2.join(y_2).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. primary selection number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attributes_list(data, columns):\n",
    "    attribute_list = pd.DataFrame()\n",
    "    attribute_list['attribute'] = columns\n",
    "    count_miss = []\n",
    "    count_unique = []\n",
    "\n",
    "    for i in tqdm(attribute_list['attribute']):\n",
    "        count_miss.append(data[i].isna().sum())\n",
    "        count_unique.append(data[i].nunique())\n",
    "    attribute_list['count_unique'] = count_unique\n",
    "    attribute_list['count_miss'] = count_miss\n",
    "    attribute_list['persent_miss'] = round(100*attribute_list['count_miss']/data.shape[0], 2)\n",
    "    gc.collect()\n",
    "    \n",
    "    return attribute_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 261/261 [00:00<00:00, 3077.30it/s]\n"
     ]
    }
   ],
   "source": [
    "attribute_list = attributes_list(train, list(train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing columns from 99% of gaps\n",
    "attribute_list_many_misses = attribute_list.attribute[(attribute_list['count_miss'] >= train.shape[0]*0.99)].values.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes2drop = attribute_list_many_misses\n",
    "train = train.drop(attributes2drop, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining parameters for classifying variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using state of art methods in credit scoring: <br>\n",
    "Feature selection according to Information value <br>\n",
    "Encoding with WOE encoder <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = ['target']\n",
    "\n",
    "attribute_list_stage_2 = attribute_list[~attribute_list.attribute.isin(attributes2drop)]\n",
    "\n",
    "categorical_cols = list(attribute_list_stage_2.attribute[attribute_list_stage_2.count_unique<=4].values)\n",
    "\n",
    "numerical_cols = list(attribute_list_stage_2.attribute[~attribute_list_stage_2.attribute.isin(categorical_cols)].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "classing_parameters = pd.DataFrame(index=numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_approx_num_prebins(x):\n",
    "    num_bins = np.histogram_bin_edges(\n",
    "        x.dropna(), bins='sqrt'\n",
    "    ).shape[0]\n",
    "\n",
    "    return num_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 245/245 [00:00<00:00, 3149.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# For numerical columns we approximate num of prebins using histogram method\n",
    "num_max_n_prebins = np.array(\n",
    "    [calc_approx_num_prebins(train[col]) for col in tqdm(numerical_cols)], dtype=np.int\n",
    ")\n",
    "num_max_n_prebins = np.clip(num_max_n_prebins, 20, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "classing_parameters.loc[numerical_cols, 'max_n_prebins'] = num_max_n_prebins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "_parameters = {\n",
    "    'prebinning_method': 'mdlp',\n",
    "    'divergence': 'iv', \n",
    "    #'min_prebin_size': 0.07, # Keep default 0.05, because larger values tend to small num of bins\n",
    "    'min_n_bins': 2, # Let it calculate automatically, but check later\n",
    "    'max_n_bins': 6, # More bins will cause ovefit, so keep it small \n",
    "    #'min_bin_size': 0.10, # To force pre-bins merge together  \n",
    "    'min_bin_n_nonevent': 10, # Important to tune it carefully, larger values tend to small num of bins and otherwise\n",
    "    'min_bin_n_event': 10, # Important to tune it carefully, larger values tend to small num of bins and otherwise\n",
    "    'monotonic_trend': 'auto_asc_desc', # Variable trend, let it selected automatically\n",
    "    'max_pvalue_policy': 'all', # Compare all bins\n",
    "    #'outlier_detector': 'range', # Helps to get more robust soluton, but not this time \n",
    "    'cat_cutoff': 0.02, # Larger values tend to small num of bins and otherwise\n",
    "    'gamma': 0.02, # Tune it carefully\n",
    "    'split_digits': 2, # The significant digits of the split points.\n",
    "    'time_limit': 60*20   \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, parameter in _parameters.items():\n",
    "    classing_parameters[name] = parameter\n",
    "    \n",
    "# Ensure dtypes are proper\n",
    "classing_parameters['max_n_prebins'] = classing_parameters['max_n_prebins'].astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classing_parameters.to_excel('coarse_classing_parameters_full.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IV. Classing parameters for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "_classing_params = classing_parameters.to_dict('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "coarse_classing_est = optbin.BinningProcess(\n",
    "    variable_names=numerical_cols, # All variable names which be used in classings \n",
    "    binning_fit_params=_classing_params, # Params for each variable\n",
    "    max_pvalue_policy='all', # Ensure. In case of something goes wrong \n",
    "    verbose=True, n_jobs=-1 # Print information and use all cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = (\n",
    "    train[numerical_cols].fillna(np.NaN), \n",
    "    train[target_col].squeeze().astype(np.int)\n",
    ")\n",
    "\n",
    "# Dypes conversion\n",
    "X_train[numerical_cols] = X_train[numerical_cols].astype(np.float)\n",
    "\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-09 17:03:20,455 | INFO : Binning process started.\n",
      "2021-10-09 17:03:20,457 | INFO : Options: check parameters.\n",
      "2021-10-09 17:03:20,459 | INFO : Dataset: number of samples: 2742.\n",
      "2021-10-09 17:03:20,460 | INFO : Dataset: number of variables: 245.\n",
      "2021-10-09 17:03:20,462 | INFO : Options: number of jobs (cores): 8.\n",
      "2021-10-09 17:03:21,821 | INFO : Binning process variable selection...\n",
      "2021-10-09 17:03:23,130 | INFO : Binning process terminated. Time: 2.6752s\n"
     ]
    }
   ],
   "source": [
    "# Supress Warnings \n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    \n",
    "    # Fit Binner\n",
    "    coarse_classing_est.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vars_cls_summary = coarse_classing_est.summary()\n",
    "possible_vars_cls_summary = all_vars_cls_summary.query('iv > 0.1 and n_bins > 1')\n",
    "possible_vars_names = possible_vars_cls_summary['name'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get train encodings\n",
    "train_encoded = coarse_classing_est.transform(\n",
    "    train[numerical_cols], \n",
    "    metric='woe',\n",
    "    metric_missing='empirical',\n",
    "    show_digits=0, check_input=True\n",
    ")[possible_vars_names]\n",
    "\n",
    "# Add target and id_cols\n",
    "train_encoded['target'] = train[target_col[0]].to_numpy().astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test encodings\n",
    "test_encoded = coarse_classing_est.transform(\n",
    "    test[numerical_cols], \n",
    "    metric='woe',\n",
    "    metric_missing='empirical',\n",
    "    show_digits=0, check_input=True\n",
    ")[possible_vars_names]\n",
    "\n",
    "# Add target and id_cols\n",
    "test_encoded['target'] = test[target_col[0]].to_numpy().astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Выборки для валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded.to_pickle('train_encoded.pkl')\n",
    "test_encoded.to_pickle('test_encoded.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
